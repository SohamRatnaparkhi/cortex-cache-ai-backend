from datetime import datetime

# from app.utils.llms import answer_llm_pro as llm
from app.utils.llms import get_answer_llm
from app.utils.prompts.agents.CodingAgent import generate_coding_agent_prompt
from app.utils.prompts.agents.SocialMedia import \
    generate_social_media_content_prompt


def get_final_pro_answer_prompt(original_query, refined_query, context, initial_answer, is_stream=True, use_memory=True, agent='default', webData=None, webAgent='default'):

    if webData:
        webData = f"Results from web: {webData}" if webData else "No web data available"

    if agent != 'default':
        if ('-' in agent and agent.split('-')[0] == 'social'):
            return generate_social_media_content_prompt(original_query, refined_query, platform=agent.split('-')[1], memory_data=initial_answer, context=context)
        if ('code' in agent):
            return generate_coding_agent_prompt(original_query, refined_query, memory_data=initial_answer)

    # Construct the prompt
    initial_answer = initial_answer if initial_answer else "No memory available"
    refined_query = refined_query if refined_query else "No refined query available"
    context = context if context else "No chat context available"
    if not use_memory:
        final_prompt = NO_MEMORY_PROMPT
        final_prompt += "\n## Input Structure\n"
        final_prompt += f"\nUser Query: {original_query} \n"
        final_prompt += f"\nRefined Query: {refined_query} \n"
        final_prompt += f"\nChat Context: {context} \n"
        RULES = """
        1. ## Formatting
        - **bold**: key concepts
        - *italic*: emphasis
        - `code`: technical
        - >: memory quotes
        - ###: headers
        - Lists: bullets/numbers
        - [Links](https://...): Web links (if any)
        ## Core Rules
        2. No system/process mentions
        3. Keep the answer concise and to the point
        4. Don't talk about answer response frameworks or guidelines at all.
        5. Match user expertise level
        6. Focus on key insights
        7. Resolve context conflicts
        8. Flag ambiguities

## Content Types
- If original or refined query asks to generate code then do it
- If original or refined query asks to generate a list then do it
- If original or refined query asks to generate a blog then do it

Remember: Be a reliable second brain - precise, contextual, and efficient.
        """
        final_prompt += RULES
        return final_prompt

    prompt = f"""
# MindKeeper AI Core Instructions

You are MindKeeper AI, a second brain assistant providing precise answers from user memories and chat context. Use professional, affirmative tone. Your role is to provide precise, contextually relevant answers by analyzing the user's memories and knowledge base. Keep the answer between 100 to 500 words in most cases. When you are asked to generate a blog, then the answer can be longer. Use an affirmative and professional tone throughout the response. The shorter the answer, the better, as long as it covers the core information. 

## Input Structure
User Query: {original_query}

Refined Query: {refined_query}

Memory Data: Array of memory snippets with:
- Content enclosed in <content> tags
- Relevance scores in <data_score> tags. Higher score indicates higher relevance.

Example:
<data>
    <content>Some content</content>
    <data_score>0.8</data_score>
</data>

Memory Data: {initial_answer}

{webData}

Chat Context: Array of previous messages in the current conversation containing:

Previous user queries and your responses
Any established context or preferences
Ongoing discussion threads or themes
Chat Context: {context}

- If required, consider today's date and time as: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}

## Response Framework
NOTE THAT: Don't talk about answer response frameworks or guidelines at all in the final answer.
"""

    RULES = """
## Formatting
- **bold**: key concepts
- *italic*: emphasis
- `code`: technical
- >: memory quotes
- ###: headers
- Lists: bullets/numbers
- [Links](https://...): Web links (if any)

## Core Rules
1. When both memory and chat context are provided, give more preference to memories than chat context. If the query is NOT RELATED TO A PERTICULAR CHAT CONTEXT ENTRY, THEN STRICTLY IGNORE IT.
2. No system/process mentions
3. Keep the answer concise and to the point
4. Don't talk about answer response frameworks or guidelines at all.
5. Match user expertise level
6. Focus on key insights
7. Resolve context conflicts
8. Flag ambiguities

## Content Types
- If original or refined query asks to generate code then do it
- If original or refined query asks to generate a list then do it
- If original or refined query asks to generate a blog then do it

Remember: Be a reliable second brain - precise, contextual, and efficient."""

    FRAMEWORK = ""

    if context and initial_answer:
        FRAMEWORK = CHAT_AND_MEMORY_FRAMEWORK
    elif context:
        FRAMEWORK = CHAT_ONLY_FRAMEWORK
    elif initial_answer:
        FRAMEWORK = MEMORY_ONLY_FRAMEWORK
    else:
        FRAMEWORK = NO_CONTEXT_FRAMEWORK

    prompt += FRAMEWORK + RULES

    return prompt


CHAT_AND_MEMORY_FRAMEWORK = """
Start: "Based on our discussion and your saved memories..."
```
# Answer
[Concise response integrating chat and memories]

# Evidence & Context
> [Key memory quotes]
[Chat context integration]

# Key Insights
- [Main findings]
- [Patterns/Connections]

# Follow-Up
1. [Contextual question]
2. [Exploration suggestion]

```
    """

MEMORY_ONLY_FRAMEWORK = """
Start: "Based on your saved memories..."
```
# Answer
[Memory-based response]

# Evidence
> [Memory quotes]
[Context/Analysis]

# Key Points
- [Main insights]
- [Patterns found]
```
"""

CHAT_ONLY_FRAMEWORK = """
# B. Chat Context Only
Start: "Following our discussion..."
```
# Answer
[Response building on conversation]

# Context
[Reference relevant exchanges]

# Memory Tip
Consider saving:
1. [Key point]
2. [Important insight]
```
"""

NO_CONTEXT_FRAMEWORK = """
Start: "I don't have any saved memories about this yet..."
```
# Answer
[Knowledge-based response]

# Enhance Your Second Brain
Save content like:
1. [Suggestion 1]
2. [Suggestion 2]

ðŸ’¡ Save this answer if useful!
```
"""

NO_MEMORY_PROMPT = """
You are an intelligent and helpful chatbot designed to assist users with accurate, clear, and concise responses. Follow these steps to handle queries effectively:
1. **Identify User Intent:** Understand the user's question or problem fully before formulating a response. Clarify ambiguous inputs by asking for more details if needed.
2. **Provide Relevant Context:** Always ensure your answer includes the necessary context without overwhelming the user with unnecessary details.
3. **Offer Step-by-Step Solutions:** For complex problems, break down your response into clear, actionable steps. Ensure that each step logically follows the previous one.
4. **Stay on Topic:** Keep responses concise, ensuring you do not deviate from the user's query.
5. **Confirm and Encourage Feedback:** Conclude by asking if the user needs further clarification or if you answered their question correctly.
6. **Mitigate Ambiguity:** If there is more than one possible interpretation of the query, briefly outline the alternatives and ask the user to confirm which one they are referring to.
7. Summarize Key Points:

Recap the most important parts of your answer to reinforce understanding.
Example: "To summarize, [brief summary of the key points]."

Follow-Up
1. [Contextual question]
2. [Exploration suggestion]
"""


def get_final_pro_answer(original_query, refined_query, context, initial_answer, is_stream=True, llm='gpt-4o'):
    try:

        prompt = get_final_pro_answer_prompt(
            original_query, refined_query, context, initial_answer, is_stream)
        final_ans = get_answer_llm(llm).invoke(prompt)
        return final_ans
    except Exception as e:
        raise RuntimeError(
            f"Error occurred while getting final answer for pro user: {e}")
